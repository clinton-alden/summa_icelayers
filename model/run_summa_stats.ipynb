{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model status: Success\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pysumma as ps\n",
    "import pysumma.plotting as psp\n",
    "import warnings\n",
    "\n",
    "# pysumma has many depreciated packages, this ignores their warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# %%\n",
    "executable = 'summa.exe'\n",
    "filemanager = '/home/cdalden/summa_setup/model/settings/file_manager_summa_2nd_half.txt'\n",
    "\n",
    "# Create a pySUMMA simulation object\n",
    "s = ps.Simulation(executable, filemanager)\n",
    "\n",
    "\n",
    "# Set the simulation start and end times from forcing file\n",
    "forcing = xr.open_dataset('/home/cdalden/summa_setup/model/forcings/colecreek_current_WY05.nc', engine='netcdf4')\n",
    "time = forcing['time']\n",
    "\n",
    "dt64 = np.datetime64(time.isel(time=0).values)\n",
    "dt = pd.to_datetime(dt64)\n",
    "start = dt.strftime('%Y-%m-%d %H:%M')\n",
    "dt64 = np.datetime64(time.isel(time=-1).values)\n",
    "dt = pd.to_datetime(dt64)\n",
    "end = dt.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "s.manager['simStartTime'] = start\n",
    "s.manager['simEndTime'] = end\n",
    "\n",
    "# Add in some additional variables so we can demonstrate plotting capabilities\n",
    "output_settings = {'period': 1, 'instant': 1, 'sum': 0, \n",
    "              'mean': 0, 'variance': 0, 'min': 0, 'max': 0}\n",
    "layer_vars = ['mLayerTemp', 'mLayerDepth', 'mLayerHeight',\n",
    "              'mLayerLiqFluxSoil', 'mLayerVolFracIce', 'mLayerVolFracLiq', \n",
    "              'mLayerVolFracWat','mLayerMatricHead', 'iLayerHeight', 'scalarSnowDepth', 'nSnow']\n",
    "\n",
    "# Create the new variables\n",
    "for var in layer_vars:\n",
    "    s.output_control[var] = output_settings\n",
    "\n",
    "# Ensure all variables have the same statistics\n",
    "all_vars = set(layer_vars + [o.name for o in s.output_control.options])\n",
    "for var in all_vars:\n",
    "    s.output_control[var] = output_settings\n",
    "\n",
    "# Set params\n",
    "s.decisions['snowLayers'] = 'jrdn1991'\n",
    "s.decisions['thCondSnow'] = 'tyen1965'\n",
    "s.decisions['snowDenNew'] = 'hedAndPom'\n",
    "s.decisions['compaction'] = 'consettl'\n",
    "s.decisions['astability'] = 'mahrtexp'\n",
    "\n",
    "s.global_hru_params['tempCritRain'] = 274.15\n",
    "s.global_hru_params['newSnowDenMin'] = 50\n",
    "s.global_hru_params['densScalGrowth'] = 0.10\n",
    "s.global_hru_params['densScalOvrbdn'] = 0.025\n",
    "s.global_hru_params['fixedThermalCond_snow'] = 0.35\n",
    "s.global_hru_params['Fcapil'] = 0.04 # intially 0.06 for salmon\n",
    "# s.global_hru_params['albedoDecayRate'] = 1.0d+5\n",
    "\n",
    "out_name = 'out_test'\n",
    "# Run the model, specify the output suffix\n",
    "# print('********** MODEL INITIALIZED **********')\n",
    "# print('********** estimated runtime ~30 seconds **********')\n",
    "s.run('local', run_suffix=out_name)\n",
    "\n",
    "# %%\n",
    "print('Model status:', s.status)\n",
    "\n",
    "\n",
    "# Create and save density and temp profile plots\n",
    "summa = s.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def justify(a, invalid_val=np.nan, axis=1, side='right'):\n",
    "    \"\"\"\n",
    "    Justifies a 2D array\n",
    "    Courtesy: https://stackoverflow.com/questions/44558215/python-justifying-numpy-array/44559180#44559180\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : ndarray\n",
    "        Input array to be justified\n",
    "    axis : int\n",
    "        Axis along which justification is to be made\n",
    "    side : str\n",
    "        Direction of justification. It could be 'left', 'right', 'up', 'down'\n",
    "        It should be 'left' or 'right' for axis=1 and 'up' or 'down' for axis=0.\n",
    "\n",
    "    \"\"\"\n",
    "    if invalid_val is np.nan:\n",
    "        mask = ~np.isnan(a)\n",
    "    else:\n",
    "        mask = a!=invalid_val\n",
    "    justified_mask = np.sort(mask,axis=axis)\n",
    "    if (side=='up') | (side=='left'):\n",
    "        justified_mask = np.flip(justified_mask,axis=axis)\n",
    "    out = np.full(a.shape, invalid_val)\n",
    "    if axis==1:\n",
    "        out[justified_mask] = a[mask]\n",
    "    else:\n",
    "        out.T[justified_mask.T] = a.T[mask.T]\n",
    "    return out\n",
    "\n",
    "\n",
    "depth = summa.isel(hru=0)['iLayerHeight']\n",
    "var = summa.isel(hru=0)['mLayerVolFracWat']\n",
    "temp = summa.isel(hru=0)['mLayerTemp']\n",
    "vmask = var != -9999\n",
    "dmask = depth != -9999\n",
    "tmask = temp != -9999\n",
    "depth.values = justify(depth.where(dmask).values)\n",
    "var.values = justify(var.where(vmask).values)\n",
    "temp.values = justify(temp.where(tmask).values)\n",
    "\n",
    "# Calculate the average at all layers\n",
    "average = temp.mean(dim='midToto')\n",
    "\n",
    "# Filter var where the average is less than 273.15\n",
    "filtered_var = var.where(average < 273.05)\n",
    "\n",
    "# filter for layers within top 1m\n",
    "max_depth = summa.isel(hru=0)['iLayerHeight'].max(dim='ifcToto') - 1\n",
    "filtered_var = filtered_var.where(summa.isel(hru=0)['iLayerHeight'] > max_depth)\n",
    "\n",
    "# Calculate the vertical derivative\n",
    "derivative = filtered_var.diff(dim='midToto')\n",
    "\n",
    "# Initialize an empty list to store the counts\n",
    "counts = []\n",
    "\n",
    "# Loop over the 'time' dimension\n",
    "for t in var.time.values:\n",
    "    # Select the derivative for the current timestep\n",
    "    derivative_t = derivative.sel(time=t)\n",
    "\n",
    "    # Filter values that are greater than or equal to 0.2 or less than or equal to -0.2\n",
    "    threshold = 0.05\n",
    "    # filtered = derivative_t.where((derivative_t >= threshold) | (derivative_t <= threshold))\n",
    "    filtered = derivative_t.where(derivative_t >= threshold)\n",
    "\n",
    "    # Count the number of layers with at least one such value\n",
    "    count = np.isfinite(filtered).sum().values\n",
    "\n",
    "    # Append the count to the list\n",
    "    counts.append(count)\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "counts = np.array(counts)\n",
    "\n",
    "crust_days = counts.sum()/24\n",
    "mean_crusts = counts.mean()\n",
    "\n",
    "# binary crust metric\n",
    "crusts_binary = np.where(counts > 0, 1, 0).sum()\n",
    "\n",
    "# Calculate '-summa['iLayerHeight'].isel(ifcToto=nSnow)'\n",
    "nSnow = summa['nSnow'].values[0] # assuming 'nSnow' is a variable in 'summa'\n",
    "hs = -summa['iLayerHeight'].isel(ifcToto=nSnow)\n",
    "\n",
    "# Apply the condition 'layer_height > 0' and sum the result\n",
    "snow_on = (hs > 0).sum()\n",
    "\n",
    "# Apply the conditions and count the number of timesteps where both conditions are true\n",
    "isothermal_days = ((hs > 0) & (average > 273.15)).sum().item()\n",
    "\n",
    "# Append netcdf\n",
    "ds = xr.open_dataset('/home/cdalden/summa_setup/analysis/crust_stats_ski_snotels.nc')\n",
    "\n",
    "# Split the string at the underscores\n",
    "parts = out_name.split(\"_\")\n",
    "\n",
    "# Extract the parts\n",
    "site = parts[0]\n",
    "model_run = parts[1]\n",
    "\n",
    "# Extract the year and convert it to a datetime\n",
    "year_str = parts[2][2:]  # Remove the 'WY' prefix\n",
    "year = int(year_str) + 2000  # Convert to an integer and add 2000\n",
    "date = datetime.datetime(year, 1, 1)  # Create a datetime object for the first day of the year\n",
    "\n",
    "\n",
    "# Check if the site does not exist in the dataset\n",
    "if site not in ds.coords['site'].values:\n",
    "    # Create a new dataset with all values set to nan\n",
    "    new_ds = xr.Dataset()\n",
    "    for var in ds.data_vars:\n",
    "        # Create a new array filled with nan, with the same dimensions as the original data\n",
    "        new_shape = [len(ds.coords[dim]) if dim != 'site' else 1 for dim in ds[var].dims]\n",
    "        new_data = np.full(new_shape, np.nan)\n",
    "        new_ds[var] = (ds[var].dims, new_data)\n",
    "\n",
    "    # Set the site coordinate to the new site\n",
    "    new_ds = new_ds.assign_coords(site=[site])\n",
    "\n",
    "    # Concatenate the new dataset with the existing one along the 'site' dimension\n",
    "    ds = xr.concat([ds, new_ds], dim='site')\n",
    "    \n",
    "# Assign a value to the 'crust_days' variable at the specified coordinates\n",
    "ds['crust_days'].loc[dict(time=date, model_run=model_run, site=site)] = crust_days\n",
    "\n",
    "# Assign a value to the 'mean_crusts' variable at the specified coordinates\n",
    "ds['mean_crusts'].loc[dict(time=date, model_run=model_run, site=site)] = mean_crusts\n",
    "\n",
    "# Assign a value to the 'crusts_binary' variable at the specified coordinates\n",
    "ds['crusts_binary'].loc[dict(time=date, model_run=model_run, site=site)] = crusts_binary\n",
    "print('number of crust days:' + str(crusts_binary/24)) # to make sure stats are working\n",
    "\n",
    "# Assign a value to the 'snow_on' variable at the specified coordinates\n",
    "ds['snow_on'].loc[dict(time=date, model_run=model_run, site=site)] = snow_on\n",
    "\n",
    "# Assign a value to the 'snow_on' variable at the specified coordinates\n",
    "ds['isothermal_days'].loc[dict(time=date, model_run=model_run, site=site)] = isothermal_days\n",
    "\n",
    "temp_file = '/home/cdalden/summa_setup/crust_stats_ski_snotels_temp.nc'\n",
    "ds.to_netcdf(temp_file, mode='w')\n",
    "os.rename(temp_file, '/home/cdalden/summa_setup/analysis/crust_stats_ski_snotels.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysumma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
