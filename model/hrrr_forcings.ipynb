{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create forcing up to current date from SNOTEL obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** generating the forcing file, please be patient **********\n",
      "********** should take ~3 minutes to run **********\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import sys\n",
    "sys.path.append('/home/cdalden/summa_setup/model/')\n",
    "from utils import lw_clr\n",
    "from utils import forcing_filler as ff\n",
    "from utils import summa_check as sc\n",
    "\n",
    "\n",
    "snotel = input('Enter the desired SNOTEL site code (ie. 1107:WA): ') + ':SNTL'\n",
    "water_year = int(2025)\n",
    "out_name = input('Enter the output file name (ie. buck_WY16): ')\n",
    "# out_path = input('Enter the output path (ie. ../model/forcings/): ')\n",
    "out_path = './forcings/'\n",
    "\n",
    "print('********** generating the forcing file, please be patient **********')\n",
    "print('********** should take ~3 minutes to run **********')\n",
    "# %% [markdown]\n",
    "# ## Use metloom API to pull snotel data\n",
    "\n",
    "# %%\n",
    "import warnings\n",
    "# pysumma has many depreciated packages, this ignores their warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='scipy')\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from metloom.pointdata import SnotelPointData\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from metsim import MetSim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from metpy.units import units\n",
    "import metpy.calc as mpcalc\n",
    "import math\n",
    "import scipy\n",
    "import os\n",
    "import shutil\n",
    "from pytz import UTC\n",
    "\n",
    "# %%\n",
    "#  Create needed directories to store metsim run and snotel CSVs\n",
    "if not os.path.exists('./input/'):\n",
    "    os.makedirs('./input/')\n",
    "\n",
    "if not os.path.exists('./out/'):\n",
    "    os.makedirs('./out/')\n",
    "\n",
    "if not os.path.exists('./snotel_csvs/'):\n",
    "    os.makedirs('./snotel_csvs/')\n",
    "\n",
    "if not os.path.exists('./forcings/'):\n",
    "    os.makedirs('./forcings/')\n",
    "\n",
    "# metsim and metloom require different formats of time and ranges, reformat here\n",
    "\n",
    "current_day = datetime.now().day\n",
    "current_day_str = str(current_day).zfill(2)\n",
    "current_month = datetime.now().month\n",
    "current_month_str = str(current_month).zfill(2)\n",
    "current_year = datetime.now().year\n",
    "\n",
    "water_year_str = str(current_year)\n",
    "start_year = water_year - 1\n",
    "start_year_str = str(start_year)\n",
    "\n",
    "start_date = datetime(start_year, 7, 3)\n",
    "end_date = datetime(current_year, current_month, current_day)\n",
    "\n",
    "spinstart = pd.to_datetime(start_year_str + '-07-03').tz_localize('UTC')\n",
    "spinend = pd.to_datetime(start_year_str + '-09-30').tz_localize('UTC')\n",
    "\n",
    "start_loc = datetime(start_year, 10, 1).replace(tzinfo=UTC)\n",
    "mask_date = datetime(start_year, 10, 2).replace(tzinfo=UTC)\n",
    "\n",
    "dates = pd.date_range('10/01/' + start_year_str, current_month_str+'/'+current_day_str+'/' + water_year_str)\n",
    "\n",
    "spin_range = pd.date_range('07/03/' + start_year_str, '09/30/' + start_year_str)\n",
    "\n",
    "# %%\n",
    "# Pull desired variables from snotel to dataframe\n",
    "snotel_point = SnotelPointData(snotel, \"MyStation\")\n",
    "df = snotel_point.get_hourly_data(\n",
    "    start_date, end_date,\n",
    "    [snotel_point.ALLOWED_VARIABLES.PRECIPITATIONACCUM, snotel_point.ALLOWED_VARIABLES.TEMP, \n",
    "     snotel_point.ALLOWED_VARIABLES.SWE, snotel_point.ALLOWED_VARIABLES.SNOWDEPTH]\n",
    ")\n",
    "\n",
    "# Specify latitude, longitude, and elevation from station metadata\n",
    "lat = snotel_point.metadata.y\n",
    "lon = snotel_point.metadata.x\n",
    "elev = snotel_point.metadata.z\n",
    "\n",
    "# Clean up the dataframe\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "replace = {'ACCUMULATED PRECIPITATION':'accppt','AIR TEMP':'airtemp', 'datetime':'time'}\n",
    "df.rename(columns=replace, inplace=True)\n",
    "df.set_index('time', inplace=True)\n",
    "\n",
    "df.to_csv('./snotel_csvs/'+out_name+'.csv')\n",
    "\n",
    "# add 'SNOWDEPTH' and 'SNOWDEPTH_units' to the droplist if it decides to work again\n",
    "try:\n",
    "    df.drop(columns=['site', 'ACCUMULATED PRECIPITATION_units', 'geometry', 'AIR TEMP_units', 'datasource', \n",
    "                 'SWE', 'SWE_units', 'SNOWDEPTH', 'SNOWDEPTH_units'], inplace=True)\n",
    "except:\n",
    "    df.drop(columns=['site', 'ACCUMULATED PRECIPITATION_units', 'geometry', 'AIR TEMP_units', 'datasource', \n",
    "                 'SWE', 'SWE_units'], inplace=True)\n",
    "    print('SNOTEL csv has no snowdepth for this run')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Fill missing timesteps from snotel data\n",
    "\n",
    "# %%\n",
    "# Convert the index of the dataframe to a DatetimeIndex\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Create a date range from the first to the last timestep\n",
    "date_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='h')\n",
    "\n",
    "# Find the missing dates\n",
    "missing_dates = date_range[~date_range.isin(df.index)]\n",
    "\n",
    "# Print the missing dates\n",
    "# print(missing_dates)\n",
    "\n",
    "# Reindex the data DataFrame with the missing dates\n",
    "# Concatenate the original DataFrame with a DataFrame containing the missing dates\n",
    "new_df = pd.concat([df, pd.DataFrame(index=missing_dates)], axis=0)\n",
    "\n",
    "# Sort the new DataFrame by the index\n",
    "new_df = new_df.sort_index()\n",
    "df = new_df\n",
    "\n",
    "# Fill NaNs for every other column\n",
    "df = df.fillna(np.nan)\n",
    "\n",
    "# Rename index\n",
    "df.index.name = 'time'\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Unit Conversions\n",
    "\n",
    "# %%\n",
    "# Covert air temperature to celsius\n",
    "df['airtemp'] = (df['airtemp'] - 32) * 5.0/9.0\n",
    "\n",
    "# Convert precipitation to mm\n",
    "df['accppt'] = df['accppt'] * 25.4\n",
    "\n",
    "# Convert from geodataframe to dataframe\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Split up data into spinup state and desired date range for MetSim\n",
    "\n",
    "# %%\n",
    "# Interpolate the missing values\n",
    "df.interpolate(inplace=True)\n",
    "\n",
    "# Seperate the data into two dataframes, before and after October 1\n",
    "# spinstart = pd.to_datetime('2014-07-03').tz_localize('UTC')\n",
    "# spinend = pd.to_datetime('2014-09-30').tz_localize('UTC')\n",
    "spinup = df.loc[spinstart:spinend].copy()\n",
    "data = df.loc[start_loc:]\n",
    "\n",
    "# Copy the dataframe a2 to a2_copy\n",
    "data_copy = data.copy()\n",
    "\n",
    "# Create a mask to identify rows where the index is less than or equal to October 2, 2023\n",
    "mask = data_copy.index <= mask_date\n",
    "\n",
    "# Set the 'precip_accum' column to 0 for rows that satisfy the mask condition\n",
    "data_copy.loc[mask, 'accppt'] = 0\n",
    "\n",
    "# Update the value of a2 to the modified copy\n",
    "data = data_copy\n",
    "\n",
    "# Calculate the difference between the maximum value of 'precip_accum' and the previous value\n",
    "spinup['pptrate'] = spinup['accppt'].cummax().diff()\n",
    "data['pptrate'] = data['accppt'].cummax().diff()\n",
    "\n",
    "# Drop accppt column\n",
    "spinup.drop(columns=['accppt'], inplace=True)\n",
    "data.drop(columns=['accppt'], inplace=True)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Generate SW from MetSim\n",
    "\n",
    "# %%\n",
    "# Create empty dataset\n",
    "shape = (len(dates), 1, 1, )\n",
    "dims = ('time', 'lat', 'lon', )\n",
    "\n",
    "# We are running only one site, at these coordinates\n",
    "lats = [lat]\n",
    "lons = [lon]\n",
    "elev = elev # meters\n",
    "coords = {'time': dates, 'lat': lats, 'lon': lons}\n",
    "\n",
    "# Create the initial met data input data structure\n",
    "met_data = xr.Dataset(coords=coords)\n",
    "\n",
    "# %%\n",
    "for varname in ['prec', 't_min', 't_max']:\n",
    "    met_data[varname] = xr.DataArray(data=np.full(shape, np.nan),\n",
    "                                     coords=coords, dims=dims,\n",
    "                                     name=varname)\n",
    "\n",
    "# %%\n",
    "# Resample the data to daily frequency and calculate the maximum and minimum temperatures\n",
    "tmax_vals = data['airtemp'].resample('D').max()\n",
    "tmin_vals = data['airtemp'].resample('D').min()\n",
    "\n",
    "# Calculate the daily precipitation values\n",
    "prec_vals = data['pptrate'].resample('D').sum()\n",
    "\n",
    "# Interpolate the temperature values to fill in any missing days\n",
    "# tmax_vals = tmax_vals.interpolate(method='linear')\n",
    "# tmin_vals = tmin_vals.interpolate(method='linear')\n",
    "\n",
    "met_data['prec'].values[:, 0, 0] = prec_vals\n",
    "\n",
    "# Assign the daily maximum and minimum temperatures to the met_data xarray, converting to Celsius\n",
    "met_data['t_min'].values[:, 0, 0] = tmin_vals\n",
    "met_data['t_max'].values[:, 0, 0] = tmax_vals\n",
    "\n",
    "met_data.to_netcdf('./input/rc_forcing.nc')\n",
    "\n",
    "# %%\n",
    "# We form the domain in a similar fashion\n",
    "# First, by creating the data structure\n",
    "coords = {'lat': lats, 'lon': lons}\n",
    "domain = xr.Dataset(coords=coords)\n",
    "domain['elev'] = xr.DataArray(data=np.full((1,1,), np.nan),\n",
    "                          coords=coords,\n",
    "                          dims=('lat', 'lon', ))\n",
    "domain['mask'] = xr.DataArray(data=np.full((1,1,), np.nan),\n",
    "                          coords=coords,\n",
    "                          dims=('lat', 'lon', ))\n",
    "\n",
    "# Add the data\n",
    "domain['elev'][0, 0] = elev\n",
    "domain['mask'][0, 0] = 1\n",
    "domain.to_netcdf('./input/rc_domain.nc')\n",
    "\n",
    "# %%\n",
    "# Finally, we create the state file - the dates are 90 days prior to \n",
    "# the MetSim run dates - as usual, create an empty data structure to\n",
    "# read the data into\n",
    "shape = (len(spin_range), 1, 1, )\n",
    "dims = ('time', 'lat', 'lon', )\n",
    "coords = {'time': spin_range, 'lat': lats, 'lon': lons}\n",
    "state = xr.Dataset(coords=coords)\n",
    "for varname in ['prec', 't_min', 't_max']:\n",
    "    state[varname] = xr.DataArray(data=np.full(shape, np.nan),\n",
    "                               coords=coords, dims=dims,\n",
    "                               name=varname)\n",
    "    \n",
    "# Resample precip to daily\n",
    "prec_vals = spinup['pptrate'].resample('D').sum()\n",
    "\n",
    "# Resample the data to daily frequency and calculate the maximum and minimum temperatures\n",
    "tmax_vals = spinup['airtemp'].resample('D').max()\n",
    "tmin_vals = spinup['airtemp'].resample('D').min()\n",
    "\n",
    "# Do precip data\n",
    "state['prec'].values[:, 0, 0] = prec_vals\n",
    "\n",
    "# And now temp data and convert to C\n",
    "state['t_min'].values[:, 0, 0] = tmin_vals\n",
    "state['t_max'].values[:, 0, 0] = tmax_vals\n",
    "state.to_netcdf('./input/rc_state.nc')\n",
    "\n",
    "# %%\n",
    "# dates = pd.date_range('10/01/2014', '09/30/2015')\n",
    "params = {\n",
    "    'time_step'    : \"60\",       \n",
    "    'start'        : dates[0],\n",
    "    'stop'         : dates[-1],\n",
    "    'forcing'      : './input/rc_forcing.nc',     \n",
    "    'domain'       : './input/rc_domain.nc',\n",
    "    'state'        : './input/rc_state.nc',\n",
    "    'forcing_fmt'  : 'netcdf',\n",
    "    'out_dir'      : './out',\n",
    "    'out_prefix': out_name,\n",
    "    'scheduler'    : 'threading',\n",
    "    'chunks'       : \n",
    "        {'lat': 1, 'lon': 1},\n",
    "    'forcing_vars' : \n",
    "        {'prec' : 'prec', 't_max': 't_max', 't_min': 't_min'},\n",
    "    'state_vars'   : \n",
    "        {'prec' : 'prec', 't_max': 't_max', 't_min': 't_min'},\n",
    "    'domain_vars'  : \n",
    "        {'elev': 'elev', 'lat': 'lat', 'lon': 'lon', 'mask': 'mask'}\n",
    "    }               \n",
    "\n",
    "# Run MetSim\n",
    "ms = MetSim(params)\n",
    "ms.run()\n",
    "output = ms.open_output().load()\n",
    "\n",
    "# Delete MetSim input and output directories to declutter, they are unnecessary\n",
    "if os.path.exists('./input/'):\n",
    "    shutil.rmtree('./input/')\n",
    "\n",
    "if os.path.exists('./out/'):\n",
    "    shutil.rmtree('./out/')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Create SUMMA forcing netCDF\n",
    "\n",
    "# %%\n",
    "out_df = output.to_dataframe()\n",
    "out_df.reset_index(inplace=True)\n",
    "out_df.set_index('time', inplace=True)\n",
    "\n",
    "# %%\n",
    "# Remove timezone from index\n",
    "data.index = data.index.tz_convert(None)\n",
    "\n",
    "# Convert precipitation rate from m hr^-1 to kg m^-2 s^-1\n",
    "data['pptrate'] = data['pptrate']/3600\n",
    "\n",
    "# Generate relative humidity assuming T_d is overnight low temperature\n",
    "# Used to calculate specific humidity and longwave radiation\n",
    "ff.fill_rel_hum(data)\n",
    "\n",
    "# Convert airtemp to Kelvin\n",
    "data['airtemp'] = (1.03*(data['airtemp']-0.9)) + 273.15 # Currier snotel temp correction\n",
    "\n",
    "# Generate pressure from hypsometric equation and site elevation (1981m)\n",
    "ff.fill_pressure(data, elev)\n",
    "data[\"airpres\"] = 80000 # Set to constant value, Pa\n",
    "\n",
    "# Generate specific humidity\n",
    "ff.fill_spec_hum(data)\n",
    "data['spechum'] = data['spechum'].clip(lower=0.001)\n",
    "\n",
    "\n",
    "# Set shortwave radiation to MetSim output\n",
    "data['SWRadAtm'] = out_df['shortwave']\n",
    "\n",
    "# Generate longwave radiation\n",
    "data['LWRadAtm'] = lw_clr.dilleyobrien1998(data['airtemp'], data['rh'])\n",
    "\n",
    "# Can alternatively use the MetSim LW radiation\n",
    "# data['LWRadAtm'] = out_df['longwave']\n",
    "\n",
    "# Set wind to 2 m/s\n",
    "data['windspd'] = 2\n",
    "\n",
    "# Fill in missing values\n",
    "data['pptrate'] = data['pptrate'].fillna(0)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['rh'])\n",
    "\n",
    "# Interpolate the missing values\n",
    "data.interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HRRR/GFS Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 46.78917694091797°N -121.75633239746094°E\n",
      "Elevation 1562.0 m asl\n",
      "Timezone b'America/Los_Angeles' b'PDT'\n",
      "Timezone difference to GMT+0 -25200 s\n",
      "                        airtemp    rh  precip       airpres   windspd  \\\n",
      "time                                                                    \n",
      "2024-10-12 07:00:00  280.967499  25.0     0.0  84349.132812  2.420744   \n",
      "2024-10-12 08:00:00  281.517487  27.0     0.0  84354.437500  3.860052   \n",
      "2024-10-12 09:00:00  281.517487  28.0     0.0  84354.437500  2.549510   \n",
      "2024-10-12 10:00:00  281.817505  25.0     0.0  84312.742188  1.300000   \n",
      "2024-10-12 11:00:00  281.167480  24.0     0.0  84243.929688  1.923538   \n",
      "2024-10-12 12:00:00  281.417480  24.0     0.0  84290.859375  2.282542   \n",
      "2024-10-12 13:00:00  279.967499  25.0     0.0  84252.460938  4.100000   \n",
      "2024-10-12 14:00:00  280.417480  24.0     0.0  84343.687500  0.200000   \n",
      "2024-10-12 15:00:00  280.367493  27.0     0.0  84398.984375  4.110961   \n",
      "2024-10-12 16:00:00  282.467499  39.0     0.0  84514.335938  5.371220   \n",
      "2024-10-12 17:00:00  282.717499  39.0     0.0  84519.664062  6.053924   \n",
      "2024-10-12 18:00:00  282.967499  37.0     0.0  84541.578125  8.015610   \n",
      "2024-10-12 19:00:00  283.617493  37.0     0.0  84576.859375  6.140033   \n",
      "2024-10-12 20:00:00  283.567505  40.0     0.0  84574.148438  5.813776   \n",
      "2024-10-12 21:00:00  283.817505  35.0     0.0  84604.296875  5.420332   \n",
      "2024-10-12 22:00:00  283.617493  33.0     0.0  84576.859375  6.389053   \n",
      "2024-10-12 23:00:00  283.367493  34.0     0.0  84571.609375  6.212890   \n",
      "2024-10-13 00:00:00  283.617493  33.0     0.0  84601.796875  5.053711   \n",
      "2024-10-13 01:00:00  283.117493  32.0     0.0  84624.515625  4.365776   \n",
      "2024-10-13 02:00:00  283.417480  27.0     0.0  84699.000000  2.745906   \n",
      "2024-10-13 03:00:00  281.917480  37.0     0.0  84617.125000  2.000000   \n",
      "2024-10-13 04:00:00  282.267487  32.0     0.0  84611.375000  6.100000   \n",
      "2024-10-13 05:00:00  282.717499  34.0     0.0  84652.578125  5.930430   \n",
      "2024-10-13 06:00:00  282.567505  35.0     0.0  84636.085938  5.842089   \n",
      "2024-10-13 07:00:00  282.867493  34.0     0.0  84652.460938  5.700877   \n",
      "2024-10-13 08:00:00  283.067505  35.0     0.0  84688.265625  6.118824   \n",
      "2024-10-13 09:00:00  282.867493  36.0     0.0  84710.609375  5.622277   \n",
      "2024-10-13 10:00:00  282.817505  37.0     0.0  84716.203125  5.408327   \n",
      "2024-10-13 11:00:00  282.917480  36.0     0.0  84721.648438  5.508176   \n",
      "2024-10-13 12:00:00  282.817505  37.0     0.0  84716.203125  5.500909   \n",
      "2024-10-13 13:00:00  283.267487  37.0     0.0  84732.382812  5.913544   \n",
      "2024-10-13 14:00:00  283.267487  36.0     0.0  84749.007812  6.791171   \n",
      "2024-10-13 15:00:00  283.767487  36.0     0.0  84776.187500  7.156815   \n",
      "2024-10-13 16:00:00  283.517487  37.0     0.0  84754.281250  7.130919   \n",
      "2024-10-13 17:00:00  284.067505  36.0     0.0  84759.187500  6.493844   \n",
      "2024-10-13 18:00:00  283.817505  34.0     0.0  84737.312500  6.198387   \n",
      "2024-10-13 19:00:00  283.817505  35.0     0.0  84720.687500  6.280127   \n",
      "2024-10-13 20:00:00  283.867493  35.0     0.0  84681.843750  6.484597   \n",
      "2024-10-13 21:00:00  283.967499  33.0     0.0  84637.367188  6.673080   \n",
      "2024-10-13 22:00:00  283.867493  33.0     0.0  84598.703125  6.777905   \n",
      "2024-10-13 23:00:00  283.817505  33.0     0.0  84562.734375  7.117584   \n",
      "2024-10-14 00:00:00  284.067505  37.0     0.0  84559.632812  7.093659   \n",
      "2024-10-14 01:00:00  284.067505  36.0     0.0  84543.000000  7.034203   \n",
      "2024-10-14 02:00:00  283.517487  35.0     0.0  84504.937500  6.649060   \n",
      "2024-10-14 03:00:00  283.817505  34.0     0.0  84512.851562  5.821512   \n",
      "2024-10-14 04:00:00  283.617493  37.0     0.0  84493.734375  5.854913   \n",
      "2024-10-14 05:00:00  283.667480  38.0     0.0  84513.046875  6.476110   \n",
      "2024-10-14 06:00:00  283.367493  42.0     0.0  84505.125000  6.648308   \n",
      "\n",
      "                     SWRadAtm   spechum    LWRadAtm  \n",
      "time                                                 \n",
      "2024-10-12 07:00:00      0.00  0.001953  234.627228  \n",
      "2024-10-12 08:00:00      0.00  0.002189  238.564285  \n",
      "2024-10-12 09:00:00      0.00  0.002270  239.352417  \n",
      "2024-10-12 10:00:00      0.00  0.002069  238.216873  \n",
      "2024-10-12 11:00:00      0.00  0.001903  234.640808  \n",
      "2024-10-12 12:00:00      0.00  0.001934  235.687744  \n",
      "2024-10-12 13:00:00      0.00  0.001826  230.480591  \n",
      "2024-10-12 14:00:00      0.00  0.001806  231.530594  \n",
      "2024-10-12 15:00:00     14.75  0.002023  233.691483  \n",
      "2024-10-12 16:00:00    142.25  0.003365  251.611176  \n",
      "2024-10-12 17:00:00    309.25  0.003422  252.776901  \n",
      "2024-10-12 18:00:00    453.75  0.003301  252.543823  \n",
      "2024-10-12 19:00:00    551.75  0.003446  255.587845  \n",
      "2024-10-12 20:00:00    599.50  0.003713  257.485962  \n",
      "2024-10-12 21:00:00    592.00  0.003302  255.049988  \n",
      "2024-10-12 22:00:00    530.50  0.003073  252.598801  \n",
      "2024-10-12 23:00:00    417.50  0.003114  252.204498  \n",
      "2024-10-13 00:00:00    265.25  0.003072  252.598801  \n",
      "2024-10-13 01:00:00     97.75  0.002881  249.537811  \n",
      "2024-10-13 02:00:00      2.25  0.002478  246.860519  \n",
      "2024-10-13 03:00:00      0.00  0.003073  247.708328  \n",
      "2024-10-13 04:00:00      0.00  0.002721  245.702911  \n",
      "2024-10-13 05:00:00      0.00  0.002979  249.220566  \n",
      "2024-10-13 06:00:00      0.00  0.003036  249.265106  \n",
      "2024-10-13 07:00:00      0.00  0.003009  249.905731  \n",
      "2024-10-13 08:00:00      0.00  0.003138  251.561920  \n",
      "2024-10-13 09:00:00      0.00  0.003184  251.364670  \n",
      "2024-10-13 10:00:00      0.00  0.003261  251.846909  \n",
      "2024-10-13 11:00:00      0.00  0.003194  251.595795  \n",
      "2024-10-13 12:00:00      0.00  0.003261  251.846909  \n",
      "2024-10-13 13:00:00      0.00  0.003360  253.943909  \n",
      "2024-10-13 14:00:00      0.00  0.003268  253.220505  \n",
      "2024-10-13 15:00:00     19.00  0.003378  255.560974  \n",
      "2024-10-13 16:00:00    147.00  0.003416  255.116974  \n",
      "2024-10-13 17:00:00    314.00  0.003447  256.976349  \n",
      "2024-10-13 18:00:00    455.00  0.003203  254.292847  \n",
      "2024-10-13 19:00:00    551.00  0.003298  255.049988  \n",
      "2024-10-13 20:00:00    594.00  0.003310  255.284271  \n",
      "2024-10-13 21:00:00    582.00  0.003143  254.220978  \n",
      "2024-10-13 22:00:00    504.00  0.003124  253.756363  \n",
      "2024-10-13 23:00:00    400.00  0.003115  253.524475  \n",
      "2024-10-14 00:00:00    239.00  0.003551  257.718292  \n",
      "2024-10-14 01:00:00     49.00  0.003456  256.976349  \n",
      "2024-10-14 02:00:00      0.00  0.003241  253.648468  \n",
      "2024-10-14 03:00:00      0.00  0.003211  254.292847  \n",
      "2024-10-14 04:00:00      0.00  0.003449  255.587845  \n",
      "2024-10-14 05:00:00      0.00  0.003553  256.546326  \n",
      "2024-10-14 06:00:00      0.00  0.003850  257.902130  \n"
     ]
    }
   ],
   "source": [
    "import openmeteo_requests\n",
    "\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "\n",
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "# Make sure all required weather variables are listed here\n",
    "# The order of variables in hourly or daily is important to assign them correctly below\n",
    "url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "params = {\n",
    "\t\"latitude\": lat,\n",
    "\t\"longitude\": lon,\n",
    "\t\"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"precipitation\", \"surface_pressure\", \"wind_speed_10m\", \"shortwave_radiation\"],\n",
    "    \"wind_speed_unit\": \"ms\",\n",
    "\t\"timezone\": \"America/Los_Angeles\",\n",
    "\t\"forecast_days\": 2,\n",
    "\t\"models\": \"gfs_hrrr\"\n",
    "}\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "# Process first location. Add a for-loop for multiple locations or weather models\n",
    "response = responses[0]\n",
    "print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "print(f\"Elevation {response.Elevation()} m asl\")\n",
    "print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        airtemp  airpres   windspd  SWRadAtm   spechum  \\\n",
      "time                                                                     \n",
      "2024-10-12 07:00:00  280.967499    80000  2.420744      0.00  0.002059   \n",
      "2024-10-12 08:00:00  281.517487    80000  3.860052      0.00  0.002308   \n",
      "2024-10-12 09:00:00  281.517487    80000  2.549510      0.00  0.002394   \n",
      "2024-10-12 10:00:00  281.817505    80000  1.300000      0.00  0.002181   \n",
      "2024-10-12 11:00:00  281.167480    80000  1.923538      0.00  0.002003   \n",
      "2024-10-12 12:00:00  281.417480    80000  2.282542      0.00  0.002038   \n",
      "2024-10-12 13:00:00  279.967499    80000  4.100000      0.00  0.001923   \n",
      "2024-10-12 14:00:00  280.417480    80000  0.200000      0.00  0.001904   \n",
      "2024-10-12 15:00:00  280.367493    80000  4.110961     14.75  0.002134   \n",
      "2024-10-12 16:00:00  282.467499    80000  5.371220    142.25  0.003555   \n",
      "2024-10-12 17:00:00  282.717499    80000  6.053924    309.25  0.003615   \n",
      "2024-10-12 18:00:00  282.967499    80000  8.015610    453.75  0.003488   \n",
      "2024-10-12 19:00:00  283.617493    80000  6.140033    551.75  0.003643   \n",
      "2024-10-12 20:00:00  283.567505    80000  5.813776    599.50  0.003925   \n",
      "2024-10-12 21:00:00  283.817505    80000  5.420332    592.00  0.003492   \n",
      "2024-10-12 22:00:00  283.617493    80000  6.389053    530.50  0.003249   \n",
      "2024-10-12 23:00:00  283.367493    80000  6.212890    417.50  0.003292   \n",
      "2024-10-13 00:00:00  283.617493    80000  5.053711    265.25  0.003249   \n",
      "2024-10-13 01:00:00  283.117493    80000  4.365776     97.75  0.003047   \n",
      "2024-10-13 02:00:00  283.417480    80000  2.745906      2.25  0.002623   \n",
      "2024-10-13 03:00:00  281.917480    80000  2.000000      0.00  0.003250   \n",
      "2024-10-13 04:00:00  282.267487    80000  6.100000      0.00  0.002878   \n",
      "2024-10-13 05:00:00  282.717499    80000  5.930430      0.00  0.003152   \n",
      "2024-10-13 06:00:00  282.567505    80000  5.842089      0.00  0.003212   \n",
      "2024-10-13 07:00:00  282.867493    80000  5.700877      0.00  0.003184   \n",
      "2024-10-13 08:00:00  283.067505    80000  6.118824      0.00  0.003322   \n",
      "2024-10-13 09:00:00  282.867493    80000  5.622277      0.00  0.003371   \n",
      "2024-10-13 10:00:00  282.817505    80000  5.408327      0.00  0.003453   \n",
      "2024-10-13 11:00:00  282.917480    80000  5.508176      0.00  0.003382   \n",
      "2024-10-13 12:00:00  282.817505    80000  5.500909      0.00  0.003453   \n",
      "2024-10-13 13:00:00  283.267487    80000  5.913544      0.00  0.003559   \n",
      "2024-10-13 14:00:00  283.267487    80000  6.791171      0.00  0.003463   \n",
      "2024-10-13 15:00:00  283.767487    80000  7.156815     19.00  0.003580   \n",
      "2024-10-13 16:00:00  283.517487    80000  7.130919    147.00  0.003619   \n",
      "2024-10-13 17:00:00  284.067505    80000  6.493844    314.00  0.003652   \n",
      "2024-10-13 18:00:00  283.817505    80000  6.198387    455.00  0.003392   \n",
      "2024-10-13 19:00:00  283.817505    80000  6.280127    551.00  0.003492   \n",
      "2024-10-13 20:00:00  283.867493    80000  6.484597    594.00  0.003504   \n",
      "2024-10-13 21:00:00  283.967499    80000  6.673080    582.00  0.003326   \n",
      "2024-10-13 22:00:00  283.867493    80000  6.777905    504.00  0.003304   \n",
      "2024-10-13 23:00:00  283.817505    80000  7.117584    400.00  0.003293   \n",
      "2024-10-14 00:00:00  284.067505    80000  7.093659    239.00  0.003754   \n",
      "2024-10-14 01:00:00  284.067505    80000  7.034203     49.00  0.003652   \n",
      "2024-10-14 02:00:00  283.517487    80000  6.649060      0.00  0.003423   \n",
      "2024-10-14 03:00:00  283.817505    80000  5.821512      0.00  0.003392   \n",
      "2024-10-14 04:00:00  283.617493    80000  5.854913      0.00  0.003643   \n",
      "2024-10-14 05:00:00  283.667480    80000  6.476110      0.00  0.003754   \n",
      "2024-10-14 06:00:00  283.367493    80000  6.648308      0.00  0.004067   \n",
      "\n",
      "                     pptrate    LWRadAtm  \n",
      "time                                      \n",
      "2024-10-12 07:00:00      0.0  234.627228  \n",
      "2024-10-12 08:00:00      0.0  238.564285  \n",
      "2024-10-12 09:00:00      0.0  239.352417  \n",
      "2024-10-12 10:00:00      0.0  238.216873  \n",
      "2024-10-12 11:00:00      0.0  234.640808  \n",
      "2024-10-12 12:00:00      0.0  235.687744  \n",
      "2024-10-12 13:00:00      0.0  230.480591  \n",
      "2024-10-12 14:00:00      0.0  231.530594  \n",
      "2024-10-12 15:00:00      0.0  233.691483  \n",
      "2024-10-12 16:00:00      0.0  251.611176  \n",
      "2024-10-12 17:00:00      0.0  252.776901  \n",
      "2024-10-12 18:00:00      0.0  252.543823  \n",
      "2024-10-12 19:00:00      0.0  255.587845  \n",
      "2024-10-12 20:00:00      0.0  257.485962  \n",
      "2024-10-12 21:00:00      0.0  255.049988  \n",
      "2024-10-12 22:00:00      0.0  252.598801  \n",
      "2024-10-12 23:00:00      0.0  252.204498  \n",
      "2024-10-13 00:00:00      0.0  252.598801  \n",
      "2024-10-13 01:00:00      0.0  249.537811  \n",
      "2024-10-13 02:00:00      0.0  246.860519  \n",
      "2024-10-13 03:00:00      0.0  247.708328  \n",
      "2024-10-13 04:00:00      0.0  245.702911  \n",
      "2024-10-13 05:00:00      0.0  249.220566  \n",
      "2024-10-13 06:00:00      0.0  249.265106  \n",
      "2024-10-13 07:00:00      0.0  249.905731  \n",
      "2024-10-13 08:00:00      0.0  251.561920  \n",
      "2024-10-13 09:00:00      0.0  251.364670  \n",
      "2024-10-13 10:00:00      0.0  251.846909  \n",
      "2024-10-13 11:00:00      0.0  251.595795  \n",
      "2024-10-13 12:00:00      0.0  251.846909  \n",
      "2024-10-13 13:00:00      0.0  253.943909  \n",
      "2024-10-13 14:00:00      0.0  253.220505  \n",
      "2024-10-13 15:00:00      0.0  255.560974  \n",
      "2024-10-13 16:00:00      0.0  255.116974  \n",
      "2024-10-13 17:00:00      0.0  256.976349  \n",
      "2024-10-13 18:00:00      0.0  254.292847  \n",
      "2024-10-13 19:00:00      0.0  255.049988  \n",
      "2024-10-13 20:00:00      0.0  255.284271  \n",
      "2024-10-13 21:00:00      0.0  254.220978  \n",
      "2024-10-13 22:00:00      0.0  253.756363  \n",
      "2024-10-13 23:00:00      0.0  253.524475  \n",
      "2024-10-14 00:00:00      0.0  257.718292  \n",
      "2024-10-14 01:00:00      0.0  256.976349  \n",
      "2024-10-14 02:00:00      0.0  253.648468  \n",
      "2024-10-14 03:00:00      0.0  254.292847  \n",
      "2024-10-14 04:00:00      0.0  255.587845  \n",
      "2024-10-14 05:00:00      0.0  256.546326  \n",
      "2024-10-14 06:00:00      0.0  257.902130  \n"
     ]
    }
   ],
   "source": [
    "# Process hourly data. The order of variables needs to be the same as requested.\n",
    "hourly = response.Hourly()\n",
    "hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "hourly_precipitation = hourly.Variables(2).ValuesAsNumpy()\n",
    "hourly_surface_pressure = hourly.Variables(3).ValuesAsNumpy()\n",
    "hourly_wind_speed_10m = hourly.Variables(4).ValuesAsNumpy()\n",
    "hourly_shortwave_radiation = hourly.Variables(5).ValuesAsNumpy()\n",
    "\n",
    "hourly_data = {\"time\": pd.date_range(\n",
    "\tstart = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")}\n",
    "hourly_data[\"airtemp\"] = hourly_temperature_2m\n",
    "hourly_data[\"rh\"] = hourly_relative_humidity_2m\n",
    "hourly_data[\"precip\"] = hourly_precipitation\n",
    "# hourly_data[\"airpres\"] = hourly_surface_pressure*100 # hPa to Pa\n",
    "hourly_data[\"airpres\"] = 80000 #constant air pressure, Pa\n",
    "hourly_data[\"windspd\"] = hourly_wind_speed_10m\n",
    "hourly_data[\"SWRadAtm\"] = hourly_shortwave_radiation\n",
    "\n",
    "hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
    "\n",
    "ff.CtoK(hourly_dataframe)\n",
    "ff.fill_spec_hum(hourly_dataframe)\n",
    "hourly_dataframe['pptrate'] = hourly_dataframe['precip']/3600\n",
    "\n",
    "# Generate longwave radiation\n",
    "hourly_dataframe['LWRadAtm'] = lw_clr.dilleyobrien1998(hourly_dataframe['airtemp'], hourly_dataframe['rh'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "hourly_dataframe = hourly_dataframe.drop(columns=['rh', 'precip'])\n",
    "# Interpolate the missing values\n",
    "hourly_dataframe.interpolate(inplace=True)\n",
    "\n",
    "# Convert the timezone-aware datetime index to naive datetime index\n",
    "hourly_dataframe.set_index('time', inplace=True)\n",
    "hourly_dataframe.index = hourly_dataframe.index.tz_localize(None)\n",
    "\n",
    "# print(hourly_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LWRadAtm</th>\n",
       "      <th>SWRadAtm</th>\n",
       "      <th>airpres</th>\n",
       "      <th>airtemp</th>\n",
       "      <th>pptrate</th>\n",
       "      <th>spechum</th>\n",
       "      <th>windspd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>294.063879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69310.658726</td>\n",
       "      <td>284.789000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011485</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 01:00:00</th>\n",
       "      <td>289.237675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69180.747683</td>\n",
       "      <td>283.450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011259</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 02:00:00</th>\n",
       "      <td>288.919046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69210.797392</td>\n",
       "      <td>283.862000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010873</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 03:00:00</th>\n",
       "      <td>283.213834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69083.384072</td>\n",
       "      <td>282.626000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 04:00:00</th>\n",
       "      <td>281.013187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69022.808716</td>\n",
       "      <td>282.008000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-14 02:00:00</th>\n",
       "      <td>253.648468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>283.517487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>6.649060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-14 03:00:00</th>\n",
       "      <td>254.292847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>283.817505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>5.821512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-14 04:00:00</th>\n",
       "      <td>255.587845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>283.617493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>5.854913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-14 05:00:00</th>\n",
       "      <td>256.546326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>283.667480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>6.476110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-14 06:00:00</th>\n",
       "      <td>257.902130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80000.000000</td>\n",
       "      <td>283.367493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>6.648308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       LWRadAtm  SWRadAtm       airpres     airtemp  pptrate  \\\n",
       "time                                                                           \n",
       "2024-10-01 00:00:00  294.063879       0.0  69310.658726  284.789000      0.0   \n",
       "2024-10-01 01:00:00  289.237675       0.0  69180.747683  283.450000      0.0   \n",
       "2024-10-01 02:00:00  288.919046       0.0  69210.797392  283.862000      0.0   \n",
       "2024-10-01 03:00:00  283.213834       0.0  69083.384072  282.626000      0.0   \n",
       "2024-10-01 04:00:00  281.013187       0.0  69022.808716  282.008000      0.0   \n",
       "...                         ...       ...           ...         ...      ...   \n",
       "2024-10-14 02:00:00  253.648468       0.0  80000.000000  283.517487      0.0   \n",
       "2024-10-14 03:00:00  254.292847       0.0  80000.000000  283.817505      0.0   \n",
       "2024-10-14 04:00:00  255.587845       0.0  80000.000000  283.617493      0.0   \n",
       "2024-10-14 05:00:00  256.546326       0.0  80000.000000  283.667480      0.0   \n",
       "2024-10-14 06:00:00  257.902130       0.0  80000.000000  283.367493      0.0   \n",
       "\n",
       "                      spechum   windspd  \n",
       "time                                     \n",
       "2024-10-01 00:00:00  0.011485  2.000000  \n",
       "2024-10-01 01:00:00  0.011259  2.000000  \n",
       "2024-10-01 02:00:00  0.010873  2.000000  \n",
       "2024-10-01 03:00:00  0.010349  2.000000  \n",
       "2024-10-01 04:00:00  0.010243  2.000000  \n",
       "...                       ...       ...  \n",
       "2024-10-14 02:00:00  0.003423  6.649060  \n",
       "2024-10-14 03:00:00  0.003392  5.821512  \n",
       "2024-10-14 04:00:00  0.003643  5.854913  \n",
       "2024-10-14 05:00:00  0.003754  6.476110  \n",
       "2024-10-14 06:00:00  0.004067  6.648308  \n",
       "\n",
       "[319 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming data and hourly_dataframe are your DataFrames\n",
    "# Combine them, using values from 'data' where the time index overlaps\n",
    "combined_dataframe = hourly_dataframe.combine_first(data)\n",
    "\n",
    "# If you want to ensure the index is sorted after combining\n",
    "combined_dataframe = combined_dataframe.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load template forcing file to preserve attributes\n",
    "template = xr.open_dataset('/home/cdalden/summa_setup/model/summa_forcing_template.nc')\n",
    "\n",
    "# Convert dataframe to xarray\n",
    "dsx = combined_dataframe.to_xarray()\n",
    "\n",
    "# Loop through variables and add attributes from template forcing file\n",
    "for data_var in dsx:\n",
    "    dsx[data_var].attrs = template[data_var].attrs\n",
    "    \n",
    "# Add hru dimension\n",
    "dsx = dsx.expand_dims(dim={'hru':1})\n",
    "\n",
    "# Add gap-filled and datastep variables\n",
    "dsx['gap_filled'] = xr.DataArray(np.ones((1,dsx.time.shape[0])),dims = ['hru','time'])\n",
    "dsx['data_step'] = 3600 # 3600 seconds for 1hr timesteps\n",
    "\n",
    "# Convert all to float64\n",
    "for var in dsx.data_vars:\n",
    "    dsx[var] = dsx[var].astype(np.float64)\n",
    "\n",
    "# Set hruID based on template\n",
    "dsx['hruId'] = (xr.DataArray(np.ones((1))*template['hruId'].values,dims = ['hru'])).astype(np.int32)\n",
    "\n",
    "# Transpose all variables to match SUMMA dimensions\n",
    "count = 0\n",
    "for var in dsx.data_vars:\n",
    "    # print(var,count)\n",
    "    count += 1\n",
    "    if count <= 7:\n",
    "        attribs = dsx[var].attrs\n",
    "        arr_t = dsx[var].values.T\n",
    "        dsx[var] = xr.DataArray(dims = ['time','hru'],data = arr_t)\n",
    "        dsx[var].attrs = attribs\n",
    "\n",
    "# Set hruID based on template\n",
    "dsx['hruId'] = (xr.DataArray(np.ones((1))*template['hruId'].values,dims = ['hru'])).astype(np.float64).fillna(0).astype(np.int32)\n",
    "\n",
    "# Set time to match SUMMA format and save\n",
    "dsx.to_netcdf(out_path+out_name+'.nc',\n",
    "                        encoding = {\"time\":\n",
    "                                        {'dtype' : 'float64',\n",
    "                                         'units' : 'hours since 1990-01-01 00:00:00',\n",
    "                                         'calendar' : 'standard'}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** generating the forcing file, please be patient **********\n",
      "********** should take ~3 minutes to run **********\n",
      "Coordinates 46.78917694091797°N -121.75633239746094°E\n",
      "Elevation 1562.0 m asl\n",
      "Timezone b'America/Los_Angeles' b'PDT'\n",
      "Timezone difference to GMT+0 -25200 s\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Create forcing up to current date from SNOTEL obs\n",
    "\n",
    "# %%\n",
    "# %%\n",
    "import sys\n",
    "sys.path.append('/home/cdalden/summa_setup/model/')\n",
    "from utils import lw_clr\n",
    "from utils import forcing_filler as ff\n",
    "from utils import summa_check as sc\n",
    "\n",
    "\n",
    "snotel = input('Enter the desired SNOTEL site code (ie. 1107:WA): ') + ':SNTL'\n",
    "water_year = int(input())\n",
    "out_name = input('Enter the output file name (ie. buck_WY16): ')\n",
    "# out_path = input('Enter the output path (ie. ../model/forcings/): ')\n",
    "out_path = '/home/cdalden/summa_setup/model/forcings/'\n",
    "\n",
    "print('********** generating the forcing file, please be patient **********')\n",
    "print('********** should take ~3 minutes to run **********')\n",
    "# %% [markdown]\n",
    "# ## Use metloom API to pull snotel data\n",
    "\n",
    "# %%\n",
    "import warnings\n",
    "# pysumma has many depreciated packages, this ignores their warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='scipy')\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from metloom.pointdata import SnotelPointData\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from metsim import MetSim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from metpy.units import units\n",
    "import metpy.calc as mpcalc\n",
    "import math\n",
    "import scipy\n",
    "import os\n",
    "import shutil\n",
    "from pytz import UTC\n",
    "\n",
    "#  Create needed directories to store metsim run and snotel CSVs\n",
    "if not os.path.exists('/home/cdalden/summa_setup/twitter_api/input/'):\n",
    "    os.makedirs('/home/cdalden/summa_setup/twitter_api/input/')\n",
    "\n",
    "if not os.path.exists('/home/cdalden/summa_setup/twitter_api/output/'):\n",
    "    os.makedirs('/home/cdalden/summa_setup/twitter_api/output/')\n",
    "\n",
    "# metsim and metloom require different formats of time and ranges, reformat here\n",
    "\n",
    "current_day = datetime.now().day\n",
    "current_day_str = str(current_day).zfill(2)\n",
    "current_month = datetime.now().month\n",
    "current_month_str = str(current_month).zfill(2)\n",
    "current_year = datetime.now().year\n",
    "\n",
    "water_year_str = str(current_year)\n",
    "start_year = water_year - 1\n",
    "start_year_str = str(start_year)\n",
    "\n",
    "start_date = datetime(start_year, 7, 3)\n",
    "end_date = datetime(current_year, current_month, current_day)\n",
    "\n",
    "spinstart = pd.to_datetime(start_year_str + '-07-03').tz_localize('UTC')\n",
    "spinend = pd.to_datetime(start_year_str + '-09-30').tz_localize('UTC')\n",
    "\n",
    "start_loc = datetime(start_year, 10, 1).replace(tzinfo=UTC)\n",
    "mask_date = datetime(start_year, 10, 2).replace(tzinfo=UTC)\n",
    "\n",
    "dates = pd.date_range('10/01/' + start_year_str, current_month_str+'/'+current_day_str+'/' + water_year_str)\n",
    "\n",
    "spin_range = pd.date_range('07/03/' + start_year_str, '09/30/' + start_year_str)\n",
    "\n",
    "# %%\n",
    "# Pull desired variables from snotel to dataframe\n",
    "snotel_point = SnotelPointData(snotel, \"MyStation\")\n",
    "df = snotel_point.get_hourly_data(\n",
    "    start_date, end_date,\n",
    "    [snotel_point.ALLOWED_VARIABLES.PRECIPITATIONACCUM, snotel_point.ALLOWED_VARIABLES.TEMP, \n",
    "     snotel_point.ALLOWED_VARIABLES.SWE, snotel_point.ALLOWED_VARIABLES.SNOWDEPTH]\n",
    ")\n",
    "\n",
    "# Specify latitude, longitude, and elevation from station metadata\n",
    "lat = snotel_point.metadata.y\n",
    "lon = snotel_point.metadata.x\n",
    "elev = snotel_point.metadata.z\n",
    "\n",
    "# Clean up the dataframe\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "replace = {'ACCUMULATED PRECIPITATION':'accppt','AIR TEMP':'airtemp', 'datetime':'time'}\n",
    "df.rename(columns=replace, inplace=True)\n",
    "df.set_index('time', inplace=True)\n",
    "\n",
    "# df.to_csv('./snotel_csvs/'+out_name+'.csv')\n",
    "\n",
    "# add 'SNOWDEPTH' and 'SNOWDEPTH_units' to the droplist if it decides to work again\n",
    "try:\n",
    "    df.drop(columns=['site', 'ACCUMULATED PRECIPITATION_units', 'geometry', 'AIR TEMP_units', 'datasource', \n",
    "                 'SWE', 'SWE_units', 'SNOWDEPTH', 'SNOWDEPTH_units'], inplace=True)\n",
    "except:\n",
    "    df.drop(columns=['site', 'ACCUMULATED PRECIPITATION_units', 'geometry', 'AIR TEMP_units', 'datasource', \n",
    "                 'SWE', 'SWE_units'], inplace=True)\n",
    "    print('SNOTEL csv has no snowdepth for this run')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Fill missing timesteps from snotel data\n",
    "\n",
    "# %%\n",
    "# Convert the index of the dataframe to a DatetimeIndex\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Create a date range from the first to the last timestep\n",
    "date_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='h')\n",
    "\n",
    "# Find the missing dates\n",
    "missing_dates = date_range[~date_range.isin(df.index)]\n",
    "\n",
    "# Print the missing dates\n",
    "# print(missing_dates)\n",
    "\n",
    "# Reindex the data DataFrame with the missing dates\n",
    "# Concatenate the original DataFrame with a DataFrame containing the missing dates\n",
    "new_df = pd.concat([df, pd.DataFrame(index=missing_dates)], axis=0)\n",
    "\n",
    "# Sort the new DataFrame by the index\n",
    "new_df = new_df.sort_index()\n",
    "df = new_df\n",
    "\n",
    "# Fill NaNs for every other column\n",
    "df = df.fillna(np.nan)\n",
    "\n",
    "# Rename index\n",
    "df.index.name = 'time'\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Unit Conversions\n",
    "\n",
    "# %%\n",
    "# Covert air temperature to celsius\n",
    "df['airtemp'] = (df['airtemp'] - 32) * 5.0/9.0\n",
    "\n",
    "# Convert precipitation to mm\n",
    "df['accppt'] = df['accppt'] * 25.4\n",
    "\n",
    "# Convert from geodataframe to dataframe\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Split up data into spinup state and desired date range for MetSim\n",
    "\n",
    "# %%\n",
    "# Interpolate the missing values\n",
    "df.interpolate(inplace=True)\n",
    "\n",
    "# Seperate the data into two dataframes, before and after October 1\n",
    "# spinstart = pd.to_datetime('2014-07-03').tz_localize('UTC')\n",
    "# spinend = pd.to_datetime('2014-09-30').tz_localize('UTC')\n",
    "spinup = df.loc[spinstart:spinend].copy()\n",
    "data = df.loc[start_loc:]\n",
    "\n",
    "# Copy the dataframe a2 to a2_copy\n",
    "data_copy = data.copy()\n",
    "\n",
    "# Create a mask to identify rows where the index is less than or equal to October 2, 2023\n",
    "mask = data_copy.index <= mask_date\n",
    "\n",
    "# Set the 'precip_accum' column to 0 for rows that satisfy the mask condition\n",
    "data_copy.loc[mask, 'accppt'] = 0\n",
    "\n",
    "# Update the value of a2 to the modified copy\n",
    "data = data_copy\n",
    "\n",
    "# Calculate the difference between the maximum value of 'precip_accum' and the previous value\n",
    "spinup['pptrate'] = spinup['accppt'].cummax().diff()\n",
    "data['pptrate'] = data['accppt'].cummax().diff()\n",
    "\n",
    "# Drop accppt column\n",
    "spinup.drop(columns=['accppt'], inplace=True)\n",
    "data.drop(columns=['accppt'], inplace=True)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Generate SW from MetSim\n",
    "\n",
    "# %%\n",
    "# Create empty dataset\n",
    "shape = (len(dates), 1, 1, )\n",
    "dims = ('time', 'lat', 'lon', )\n",
    "\n",
    "# We are running only one site, at these coordinates\n",
    "lats = [lat]\n",
    "lons = [lon]\n",
    "elev = elev # meters\n",
    "coords = {'time': dates, 'lat': lats, 'lon': lons}\n",
    "\n",
    "# Create the initial met data input data structure\n",
    "met_data = xr.Dataset(coords=coords)\n",
    "\n",
    "# %%\n",
    "for varname in ['prec', 't_min', 't_max']:\n",
    "    met_data[varname] = xr.DataArray(data=np.full(shape, np.nan),\n",
    "                                     coords=coords, dims=dims,\n",
    "                                     name=varname)\n",
    "\n",
    "# %%\n",
    "# Resample the data to daily frequency and calculate the maximum and minimum temperatures\n",
    "tmax_vals = data['airtemp'].resample('D').max()\n",
    "tmin_vals = data['airtemp'].resample('D').min()\n",
    "\n",
    "# Calculate the daily precipitation values\n",
    "prec_vals = data['pptrate'].resample('D').sum()\n",
    "\n",
    "# Interpolate the temperature values to fill in any missing days\n",
    "# tmax_vals = tmax_vals.interpolate(method='linear')\n",
    "# tmin_vals = tmin_vals.interpolate(method='linear')\n",
    "\n",
    "met_data['prec'].values[:, 0, 0] = prec_vals\n",
    "\n",
    "# Assign the daily maximum and minimum temperatures to the met_data xarray, converting to Celsius\n",
    "met_data['t_min'].values[:, 0, 0] = tmin_vals\n",
    "met_data['t_max'].values[:, 0, 0] = tmax_vals\n",
    "\n",
    "met_data.to_netcdf('/home/cdalden/summa_setup/twitter_api/input/rc_forcing.nc')\n",
    "\n",
    "# %%\n",
    "# We form the domain in a similar fashion\n",
    "# First, by creating the data structure\n",
    "coords = {'lat': lats, 'lon': lons}\n",
    "domain = xr.Dataset(coords=coords)\n",
    "domain['elev'] = xr.DataArray(data=np.full((1,1,), np.nan),\n",
    "                          coords=coords,\n",
    "                          dims=('lat', 'lon', ))\n",
    "domain['mask'] = xr.DataArray(data=np.full((1,1,), np.nan),\n",
    "                          coords=coords,\n",
    "                          dims=('lat', 'lon', ))\n",
    "\n",
    "# Add the data\n",
    "domain['elev'][0, 0] = elev\n",
    "domain['mask'][0, 0] = 1\n",
    "domain.to_netcdf('/home/cdalden/summa_setup/twitter_api/input/rc_domain.nc')\n",
    "\n",
    "# %%\n",
    "# Finally, we create the state file - the dates are 90 days prior to \n",
    "# the MetSim run dates - as usual, create an empty data structure to\n",
    "# read the data into\n",
    "shape = (len(spin_range), 1, 1, )\n",
    "dims = ('time', 'lat', 'lon', )\n",
    "coords = {'time': spin_range, 'lat': lats, 'lon': lons}\n",
    "state = xr.Dataset(coords=coords)\n",
    "for varname in ['prec', 't_min', 't_max']:\n",
    "    state[varname] = xr.DataArray(data=np.full(shape, np.nan),\n",
    "                               coords=coords, dims=dims,\n",
    "                               name=varname)\n",
    "    \n",
    "# Resample precip to daily\n",
    "prec_vals = spinup['pptrate'].resample('D').sum()\n",
    "\n",
    "# Resample the data to daily frequency and calculate the maximum and minimum temperatures\n",
    "tmax_vals = spinup['airtemp'].resample('D').max()\n",
    "tmin_vals = spinup['airtemp'].resample('D').min()\n",
    "\n",
    "# Do precip data\n",
    "state['prec'].values[:, 0, 0] = prec_vals\n",
    "\n",
    "# And now temp data and convert to C\n",
    "state['t_min'].values[:, 0, 0] = tmin_vals\n",
    "state['t_max'].values[:, 0, 0] = tmax_vals\n",
    "state.to_netcdf('/home/cdalden/summa_setup/twitter_api/input/rc_state.nc')\n",
    "\n",
    "# %%\n",
    "# dates = pd.date_range('10/01/2014', '09/30/2015')\n",
    "params = {\n",
    "    'time_step'    : \"60\",       \n",
    "    'start'        : dates[0],\n",
    "    'stop'         : dates[-1],\n",
    "    'forcing'      : '/home/cdalden/summa_setup/twitter_api/input/rc_forcing.nc',     \n",
    "    'domain'       : '/home/cdalden/summa_setup/twitter_api/input/rc_domain.nc',\n",
    "    'state'        : '/home/cdalden/summa_setup/twitter_api/input/rc_state.nc',\n",
    "    'forcing_fmt'  : 'netcdf',\n",
    "    'out_dir'      : '/home/cdalden/summa_setup/twitter_api/output/',\n",
    "    'out_prefix': out_name,\n",
    "    'scheduler'    : 'threading',\n",
    "    'chunks'       : \n",
    "        {'lat': 1, 'lon': 1},\n",
    "    'forcing_vars' : \n",
    "        {'prec' : 'prec', 't_max': 't_max', 't_min': 't_min'},\n",
    "    'state_vars'   : \n",
    "        {'prec' : 'prec', 't_max': 't_max', 't_min': 't_min'},\n",
    "    'domain_vars'  : \n",
    "        {'elev': 'elev', 'lat': 'lat', 'lon': 'lon', 'mask': 'mask'}\n",
    "    }               \n",
    "\n",
    "# Run MetSim\n",
    "ms = MetSim(params)\n",
    "ms.run()\n",
    "output = ms.open_output().load()\n",
    "\n",
    "# Delete MetSim input and output directories to declutter, they are unnecessary\n",
    "if os.path.exists('/home/cdalden/summa_setup/twitter_api/input/'):\n",
    "    shutil.rmtree('/home/cdalden/summa_setup/twitter_api/input/')\n",
    "\n",
    "if os.path.exists('/home/cdalden/summa_setup/twitter_api/output/'):\n",
    "    shutil.rmtree('/home/cdalden/summa_setup/twitter_api/output/')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Create SUMMA forcing netCDF\n",
    "\n",
    "# %%\n",
    "out_df = output.to_dataframe()\n",
    "out_df.reset_index(inplace=True)\n",
    "out_df.set_index('time', inplace=True)\n",
    "\n",
    "# %%\n",
    "# Remove timezone from index\n",
    "data.index = data.index.tz_convert(None)\n",
    "\n",
    "# Convert precipitation rate from m hr^-1 to kg m^-2 s^-1\n",
    "data['pptrate'] = data['pptrate']/3600\n",
    "\n",
    "# Generate relative humidity assuming T_d is overnight low temperature\n",
    "# Used to calculate specific humidity and longwave radiation\n",
    "ff.fill_rel_hum(data)\n",
    "\n",
    "# Convert airtemp to Kelvin\n",
    "data['airtemp'] = (1.03*(data['airtemp']-0.9)) + 273.15 # Currier snotel temp correction\n",
    "\n",
    "# Generate pressure from hypsometric equation and site elevation (1981m)\n",
    "ff.fill_pressure(data, elev)\n",
    "data[\"airpres\"] = 80000 # Set to constant value, Pa\n",
    "\n",
    "# Generate specific humidity\n",
    "ff.fill_spec_hum(data)\n",
    "data['spechum'] = data['spechum'].clip(lower=0.001)\n",
    "\n",
    "\n",
    "# Set shortwave radiation to MetSim output\n",
    "data['SWRadAtm'] = out_df['shortwave']\n",
    "\n",
    "# Generate longwave radiation\n",
    "data['LWRadAtm'] = lw_clr.dilleyobrien1998(data['airtemp'], data['rh'])\n",
    "\n",
    "# Can alternatively use the MetSim LW radiation\n",
    "# data['LWRadAtm'] = out_df['longwave']\n",
    "\n",
    "# Set wind to 2 m/s\n",
    "data['windspd'] = 2\n",
    "\n",
    "# Fill in missing values\n",
    "data['pptrate'] = data['pptrate'].fillna(0)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['rh'])\n",
    "\n",
    "# Interpolate the missing values\n",
    "data.interpolate(inplace=True)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## HRRR/GFS Forecast\n",
    "\n",
    "# %%\n",
    "import openmeteo_requests\n",
    "\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "\n",
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "# Make sure all required weather variables are listed here\n",
    "# The order of variables in hourly or daily is important to assign them correctly below\n",
    "url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "params = {\n",
    "\t\"latitude\": lat,\n",
    "\t\"longitude\": lon,\n",
    "\t\"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"precipitation\", \"surface_pressure\", \"wind_speed_10m\", \"shortwave_radiation\"],\n",
    "    \"wind_speed_unit\": \"ms\",\n",
    "\t\"timezone\": \"America/Los_Angeles\",\n",
    "\t\"forecast_days\": 2,\n",
    "\t\"models\": \"gfs_hrrr\"\n",
    "}\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "# Process first location. Add a for-loop for multiple locations or weather models\n",
    "response = responses[0]\n",
    "print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "print(f\"Elevation {response.Elevation()} m asl\")\n",
    "print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
    "\n",
    "# %%\n",
    "# Process hourly data. The order of variables needs to be the same as requested.\n",
    "hourly = response.Hourly()\n",
    "hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "hourly_precipitation = hourly.Variables(2).ValuesAsNumpy()\n",
    "hourly_surface_pressure = hourly.Variables(3).ValuesAsNumpy()\n",
    "hourly_wind_speed_10m = hourly.Variables(4).ValuesAsNumpy()\n",
    "hourly_shortwave_radiation = hourly.Variables(5).ValuesAsNumpy()\n",
    "\n",
    "hourly_data = {\"time\": pd.date_range(\n",
    "\tstart = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")}\n",
    "hourly_data[\"airtemp\"] = hourly_temperature_2m\n",
    "hourly_data[\"rh\"] = hourly_relative_humidity_2m\n",
    "hourly_data[\"precip\"] = hourly_precipitation\n",
    "# hourly_data[\"airpres\"] = hourly_surface_pressure*100 # hPa to Pa\n",
    "hourly_data[\"airpres\"] = 80000 #constant air pressure, Pa\n",
    "hourly_data[\"windspd\"] = hourly_wind_speed_10m\n",
    "hourly_data[\"SWRadAtm\"] = hourly_shortwave_radiation\n",
    "\n",
    "hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
    "\n",
    "ff.CtoK(hourly_dataframe)\n",
    "ff.fill_spec_hum(hourly_dataframe)\n",
    "hourly_dataframe['pptrate'] = hourly_dataframe['precip']/3600\n",
    "\n",
    "# Generate longwave radiation\n",
    "hourly_dataframe['LWRadAtm'] = lw_clr.dilleyobrien1998(hourly_dataframe['airtemp'], hourly_dataframe['rh'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "hourly_dataframe = hourly_dataframe.drop(columns=['rh', 'precip'])\n",
    "# Interpolate the missing values\n",
    "hourly_dataframe.interpolate(inplace=True)\n",
    "\n",
    "# Convert the timezone-aware datetime index to naive datetime index\n",
    "hourly_dataframe.set_index('time', inplace=True)\n",
    "hourly_dataframe.index = hourly_dataframe.index.tz_localize(None)\n",
    "\n",
    "# print(hourly_dataframe)\n",
    "\n",
    "# %%\n",
    "# Assuming data and hourly_dataframe are your DataFrames\n",
    "# Combine them, using values from 'data' where the time index overlaps\n",
    "combined_dataframe = hourly_dataframe.combine_first(data)\n",
    "\n",
    "# If you want to ensure the index is sorted after combining\n",
    "combined_dataframe = combined_dataframe.sort_index()\n",
    "\n",
    "# %%\n",
    "# Load template forcing file to preserve attributes\n",
    "template = xr.open_dataset('/home/cdalden/summa_setup/model/summa_forcing_template.nc')\n",
    "\n",
    "# Convert dataframe to xarray\n",
    "dsx = combined_dataframe.to_xarray()\n",
    "\n",
    "# Loop through variables and add attributes from template forcing file\n",
    "for data_var in dsx:\n",
    "    dsx[data_var].attrs = template[data_var].attrs\n",
    "    \n",
    "# Add hru dimension\n",
    "dsx = dsx.expand_dims(dim={'hru':1})\n",
    "\n",
    "# Add gap-filled and datastep variables\n",
    "dsx['gap_filled'] = xr.DataArray(np.ones((1,dsx.time.shape[0])),dims = ['hru','time'])\n",
    "dsx['data_step'] = 3600 # 3600 seconds for 1hr timesteps\n",
    "\n",
    "# Convert all to float64\n",
    "for var in dsx.data_vars:\n",
    "    dsx[var] = dsx[var].astype(np.float64)\n",
    "\n",
    "# Set hruID based on template\n",
    "dsx['hruId'] = (xr.DataArray(np.ones((1))*template['hruId'].values,dims = ['hru'])).astype(np.int32)\n",
    "\n",
    "# Transpose all variables to match SUMMA dimensions\n",
    "count = 0\n",
    "for var in dsx.data_vars:\n",
    "    # print(var,count)\n",
    "    count += 1\n",
    "    if count <= 7:\n",
    "        attribs = dsx[var].attrs\n",
    "        arr_t = dsx[var].values.T\n",
    "        dsx[var] = xr.DataArray(dims = ['time','hru'],data = arr_t)\n",
    "        dsx[var].attrs = attribs\n",
    "\n",
    "# Set hruID based on template\n",
    "dsx['hruId'] = (xr.DataArray(np.ones((1))*template['hruId'].values,dims = ['hru'])).astype(np.float64).fillna(0).astype(np.int32)\n",
    "\n",
    "# Set time to match SUMMA format and save\n",
    "dsx.to_netcdf(out_path+out_name+'.nc',\n",
    "                        encoding = {\"time\":\n",
    "                                        {'dtype' : 'float64',\n",
    "                                         'units' : 'hours since 1990-01-01 00:00:00',\n",
    "                                         'calendar' : 'standard'}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysumma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
